{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75cc1961",
   "metadata": {},
   "source": [
    "# ðŸ§­ Developing a Data Catalog with AWS Glue Crawlers\n",
    "\n",
    "**Mode:** Console-only â€¢ **Region:** `us-east-1`\n",
    "\n",
    "### ðŸŽ¯ Objective\n",
    "Build a Glue **Data Catalog** by running a **Crawler** over CSV data in S3.\n",
    "\n",
    "### Why this matters\n",
    "Glue Crawlers automatically discover schema (columns, data types, partitions) and create tables in the **Glue Data Catalog** that services like **Athena**, **Redshift Spectrum**, and **EMR** can query.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf81241",
   "metadata": {},
   "source": [
    "## âœ… Prerequisites\n",
    "- AWS account with access to **S3, IAM, Glue**.\n",
    "- Create an S3 bucket (globally unique): **`glue-lab24-crawler-us-east-1`**\n",
    "- Upload your files into: `s3://glue-lab24-crawler-us-east-1/sales-data/`\n",
    "  - `orders_with_header.csv`\n",
    "  - `customers_with_header.csv`\n",
    "- Youâ€™ll create an IAM role **AWSGlueServiceRoleLab24** below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c86528",
   "metadata": {},
   "source": [
    "## 1) Create IAM role for the crawler\n",
    "1. AWS Console â†’ **IAM â†’ Roles â†’ Create role**  \n",
    "2. **Trusted entity**: AWS service â†’ **Glue**  \n",
    "3. **Permissions**: attach\n",
    "   - `AWSGlueServiceRole`\n",
    "   - `AmazonS3FullAccess` *(or a leastâ€‘privilege policy to your bucket path)*  \n",
    "4. **Role name**: `AWSGlueServiceRoleLab24`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92063250",
   "metadata": {},
   "source": [
    "## 2) Create a new Crawler\n",
    "1. AWS Console â†’ **AWS Glue â†’ Crawlers â†’ Create crawler**\n",
    "2. **Name**: `sales-data-crawler24`\n",
    "3. **Data source**: **S3**\n",
    "4. **S3 path**: `s3://glue-lab24-crawler-us-east-1/sales-data/`\n",
    "5. **IAM role**: *Choose existing* â†’ `AWSGlueServiceRoleLab24`\n",
    "6. **Target** â†’ **Create a database**: `sales_data_db24`\n",
    "7. **Schedule**: *On demand*\n",
    "8. **Table name changes**: keep defaults\n",
    "9. **Create crawler**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a1a8d",
   "metadata": {},
   "source": [
    "## 3) Run the crawler and verify tables\n",
    "1. Select **sales-data-crawler24 â†’ Run**. Wait for **Completed**.\n",
    "2. Go to **Glue â†’ Data Catalog â†’ Databases â†’ sales_data_db24 â†’ Tables**.\n",
    "3. You should see tables inferred for your CSVs (example: `orders_with_header`, `customers_with_header`).\n",
    "4. Open a table â†’ **Schema** to review columns and data types.\n",
    "\n",
    "### Notes\n",
    "- If headers arenâ€™t detected or delimiters differ, youâ€™ll fix that in **Lab 25 (Custom Classifier)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c623cf",
   "metadata": {},
   "source": [
    "## ðŸ§¹ Cleanup\n",
    "- Stop/delete the crawler if no longer needed.\n",
    "- Delete the IAM roles and S3 buckets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f719a0cd",
   "metadata": {},
   "source": [
    "## ðŸ§­ Reflection\n",
    "- **Crawler** = automated schema discovery.  \n",
    "- **Data Catalog** = central metadata store for your lakehouse. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
