{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf0a9972",
   "metadata": {},
   "source": [
    "\n",
    "# üß© AWS Redshift S3 Integration Lab \n",
    "\n",
    "**Objective:** Learn how to load a **CSV file** from an **S3 bucket** into **Amazon Redshift** using the `COPY` command.  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## üß≠ Lab Overview\n",
    "\n",
    "In this lab, you will:\n",
    "1. Prepare and verify your S3 bucket and IAM role.\n",
    "2. Create a table in Amazon Redshift matching your file structure.\n",
    "3. Use the `COPY` command to load data from S3 to Redshift.\n",
    "4. Validate and analyze the data with SQL queries.\n",
    "\n",
    "> üß† **Note:** This lab assumes your Redshift cluster is already running, the IAM role is attached, and your S3 bucket (created using boto3 or console) already contains `orders.csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a6da0b",
   "metadata": {},
   "source": [
    "\n",
    "## ‚öôÔ∏è Prerequisites\n",
    "\n",
    "Before starting, ensure that you have:\n",
    "\n",
    "1. **Redshift Cluster Running**\n",
    "   - Database name: e.g., `dev`\n",
    "   - User: `admin`\n",
    "   - Status: `available`\n",
    "\n",
    "2. **IAM Role with S3 Read Access**\n",
    "   - Role attached to the Redshift cluster.\n",
    "   - Policy: `AmazonS3ReadOnlyAccess`.\n",
    "\n",
    "3. **S3 Bucket and File**\n",
    "   - Existing S3 bucket: e.g., `my-demo-bucket-12345`\n",
    "   - File path: `s3://my-demo-bucket-12345/orders.csv`\n",
    "   - File format: **CSV, no header**\n",
    "   - File structure:\n",
    "\n",
    "```\n",
    "order_id,order_date,customer_id,order_status\n",
    "1001,2023-01-03,25,SHIPPED\n",
    "1002,2023-01-05,47,CANCELLED\n",
    "1003,2023-01-07,31,PENDING\n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1c7b87",
   "metadata": {},
   "source": [
    "\n",
    "## üß± Step 1: Create Table in Redshift\n",
    "\n",
    "We first create a table matching the structure of the CSV file.\n",
    "\n",
    "```sql\n",
    "CREATE TABLE orders_redshift (\n",
    "    order_id INT,\n",
    "    order_date DATE,\n",
    "    customer_id INT,\n",
    "    order_status VARCHAR(20)\n",
    ");\n",
    "```\n",
    "\n",
    "‚úÖ **Explanation:**\n",
    "- The CSV has **no header**, so columns must match file order exactly.\n",
    "- `order_status` is the **last column**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a644205e",
   "metadata": {},
   "source": [
    "\n",
    "## üì• Step 2: Load Data from S3 (COPY Command)\n",
    "\n",
    "Run the following command from the **Redshift Query Editor v2** or your preferred SQL client.\n",
    "\n",
    "```sql\n",
    "COPY orders_redshift\n",
    "FROM 's3://my-demo-bucket-12345/orders.csv'\n",
    "IAM_ROLE 'arn:aws:iam::111122223333:role/MyRedshiftS3Role'\n",
    "FORMAT AS CSV\n",
    "DELIMITER ','\n",
    "REMOVEQUOTES;\n",
    "```\n",
    "\n",
    "‚úÖ **Explanation:**\n",
    "- `IAM_ROLE` ‚Üí ARN of the IAM role with S3 read access.\n",
    "- `DELIMITER ','` ‚Üí Defines CSV column separator.\n",
    "- `REMOVEQUOTES` ‚Üí Strips double quotes from text values.\n",
    "- **Do not** use `IGNOREHEADER` since this file has no header.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d4e0c7",
   "metadata": {},
   "source": [
    "\n",
    "## üîç Step 3: Verify Data Load\n",
    "\n",
    "Use simple queries to validate and inspect the loaded data.\n",
    "\n",
    "```sql\n",
    "-- Preview sample records\n",
    "SELECT * FROM orders_redshift LIMIT 10;\n",
    "\n",
    "-- Total number of orders\n",
    "SELECT COUNT(*) AS total_orders FROM orders_redshift;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f88800",
   "metadata": {},
   "source": [
    "\n",
    "## üìä Step 4: Analyze Orders by Status\n",
    "\n",
    "```sql\n",
    "-- Count orders by status\n",
    "SELECT order_status, COUNT(*) AS total_by_status\n",
    "FROM orders_redshift\n",
    "GROUP BY order_status\n",
    "ORDER BY total_by_status DESC;\n",
    "```\n",
    "‚úÖ **Expected Output Example:**\n",
    "| order_status | total_by_status |\n",
    "|---------------|----------------|\n",
    "| SHIPPED       | 1540           |\n",
    "| PENDING       | 732            |\n",
    "| CANCELLED     | 128            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b190b44c",
   "metadata": {},
   "source": [
    "\n",
    "## üßπ Step 5: Cleanup (Optional)\n",
    "\n",
    "If you want to remove the table after verification:\n",
    "\n",
    "```sql\n",
    "DROP TABLE orders_redshift;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Reflection\n",
    "\n",
    "In this lab, you learned how to:\n",
    "- Load **headerless CSV data** from S3 into Redshift.  \n",
    "- Define explicit **column order and types**.  \n",
    "- Analyze loaded data using basic SQL queries.  \n",
    "\n",
    "This process demonstrates how **buckets created via boto3 or console** can seamlessly integrate with **Redshift COPY operations**, enabling easy ETL workflows.\n",
    "\n",
    "---\n",
    "\n",
    "## ü™û References\n",
    "\n",
    "- [Amazon Redshift COPY Command](https://docs.aws.amazon.com/redshift/latest/dg/r_COPY_command_examples.html)\n",
    "- [Redshift IAM Role for S3 Access](https://docs.aws.amazon.com/redshift/latest/mgmt/authorizing-redshift-service.html)\n",
    "- [Redshift Query Editor v2 Guide](https://docs.aws.amazon.com/redshift/latest/mgmt/query-editor-v2.html)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
