{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d83bc3c6",
   "metadata": {},
   "source": [
    "\n",
    "# PySpark DataFrame API Examples\n",
    "\n",
    "This notebook demonstrates various **PySpark DataFrame operations** \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bd65bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder.appName(\"PySparkDataFrameExamples\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbf085d",
   "metadata": {},
   "source": [
    "### 1Ô∏è‚É£ Create a DataFrame from a Python Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60916229",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = [(\"Ravi\", 25, \"Bengaluru\"),\n",
    "        (\"Priya\", 30, \"Hyderabad\"),\n",
    "        (\"Ankit\", 28, \"Pune\"),\n",
    "        (\"Lakshmi\", 32, \"Chennai\")]\n",
    "columns = [\"Name\", \"Age\", \"City\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2d48ba",
   "metadata": {},
   "source": [
    "### 2Ô∏è‚É£ Selecting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6f5cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.select(\"Name\", \"Age\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3399f2",
   "metadata": {},
   "source": [
    "### 3Ô∏è‚É£ Filtering Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f67cba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.filter(df.Age > 28).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc783aa9",
   "metadata": {},
   "source": [
    "### 4Ô∏è‚É£ Add or Transform Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66059881",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_new = df.withColumn(\"Age_After_5_Years\", df.Age + 5)\n",
    "df_new.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007f2e47",
   "metadata": {},
   "source": [
    "### 5Ô∏è‚É£ Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe669e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_renamed = df.withColumnRenamed(\"City\", \"Location\")\n",
    "df_renamed.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bb5826",
   "metadata": {},
   "source": [
    "### 6Ô∏è‚É£ Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b296f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_dropped = df.drop(\"City\")\n",
    "df_dropped.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61547be9",
   "metadata": {},
   "source": [
    "### 7Ô∏è‚É£ Group By and Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634897e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "group_data = [(\"IT\", 40000), (\"HR\", 25000), (\"IT\", 45000), (\"Finance\", 30000)]\n",
    "df_group = spark.createDataFrame(group_data, [\"Department\", \"Salary\"])\n",
    "\n",
    "df_group.groupBy(\"Department\").agg(\n",
    "    F.avg(\"Salary\").alias(\"Avg_Salary\"),\n",
    "    F.max(\"Salary\").alias(\"Max_Salary\"),\n",
    "    F.count(\"*\").alias(\"Count\")\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac37346",
   "metadata": {},
   "source": [
    "### 8Ô∏è‚É£ Sorting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1044ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.orderBy(F.desc(\"Age\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1243670",
   "metadata": {},
   "source": [
    "### 9Ô∏è‚É£ Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476f47b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dup_data = [(\"Ravi\", \"IT\"), (\"Ravi\", \"IT\"), (\"Priya\", \"HR\")]\n",
    "df_dup = spark.createDataFrame(dup_data, [\"Name\", \"Dept\"])\n",
    "df_dup.dropDuplicates().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fc4105",
   "metadata": {},
   "source": [
    "### üîü Joins Between DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1285948",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dept_data = [(\"Ravi\", \"IT\"), (\"Priya\", \"HR\"), (\"Ankit\", \"Finance\")]\n",
    "df_dept = spark.createDataFrame(dept_data, [\"Name\", \"Department\"])\n",
    "\n",
    "joined = df.join(df_dept, on=\"Name\", how=\"inner\")\n",
    "joined.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bee8df8",
   "metadata": {},
   "source": [
    "### 11Ô∏è‚É£ Handling Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed64589",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "null_data = [(\"Ravi\", None), (\"Priya\", 30), (\"Ankit\", None)]\n",
    "df_null = spark.createDataFrame(null_data, [\"Name\", \"Age\"])\n",
    "\n",
    "df_null.fillna({\"Age\": 25}).show()   # Replace nulls\n",
    "df_null.na.drop().show()              # Drop nulls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720e721d",
   "metadata": {},
   "source": [
    "### 12Ô∏è‚É£ Conditional Column with `when` and `otherwise`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeabf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_cond = df.withColumn(\"Category\", F.when(df.Age > 30, \"Senior\").otherwise(\"Junior\"))\n",
    "df_cond.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a74840",
   "metadata": {},
   "source": [
    "### 13Ô∏è‚É£ DataFrame Summary and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930fe781",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.describe().show()\n",
    "df.summary().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619d6360",
   "metadata": {},
   "source": [
    "### 14Ô∏è‚É£ Repartition and Coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61959f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Repartition to 4 partitions:\")\n",
    "df_repart = df.repartition(4)\n",
    "print(df_repart.rdd.getNumPartitions())\n",
    "\n",
    "print(\"Coalesce back to 2 partitions:\")\n",
    "df_coalesce = df_repart.coalesce(2)\n",
    "print(df_coalesce.rdd.getNumPartitions())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe978ea",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Summary of APIs Covered\n",
    "\n",
    "| Operation | API | Description |\n",
    "|------------|-----|-------------|\n",
    "| Create DataFrame | `createDataFrame()` | From list/collection |\n",
    "| Select Columns | `select()` | Choose specific columns |\n",
    "| Filter Rows | `filter()` | Apply condition filters |\n",
    "| Add Column | `withColumn()` | Add or modify a column |\n",
    "| Rename Column | `withColumnRenamed()` | Rename existing column |\n",
    "| Drop Column | `drop()` | Remove a column |\n",
    "| Group & Aggregate | `groupBy().agg()` | Aggregate functions |\n",
    "| Sort | `orderBy()` | Ascending/Descending |\n",
    "| Remove Duplicates | `dropDuplicates()` | Keep unique rows |\n",
    "| Join | `join()` | Combine multiple DataFrames |\n",
    "| Handle Nulls | `fillna()`, `na.drop()` | Manage missing values |\n",
    "| Conditional Logic | `when().otherwise()` | Add derived columns |\n",
    "| Statistics | `describe()`, `summary()` | Summary metrics |\n",
    "| Partition Control | `repartition()`, `coalesce()` | Manage partitions |\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
