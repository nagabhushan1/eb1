{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6194760d",
   "metadata": {},
   "source": [
    "# 01_Spark_Setup_Docker.ipynb\n",
    "\n",
    "## üöÄ Apache Spark Setup using Docker\n",
    "This notebook provides step-by-step instructions to set up and run **Apache Spark 2.x** using Docker. It uses the official **Jupyter All-Spark Notebook** image, which comes preinstalled with Spark, Hadoop, Python, and Jupyter.\n",
    "\n",
    "---\n",
    "\n",
    "### üß∞ Prerequisites\n",
    "- Docker must already be installed and running.\n",
    "- Check your Docker version:\n",
    "```bash\n",
    "docker --version\n",
    "```\n",
    "- Ensure internet access to pull the image.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ab492d",
   "metadata": {},
   "source": [
    "## üê≥ Step 1: Pull the Spark Notebook Docker Image\n",
    "Pull the official Jupyter All-Spark-Notebook image (tag `95f855f8e55f`) from Docker Hub.\n",
    "```bash\n",
    "docker pull jupyter/all-spark-notebook:95f855f8e55f\n",
    "```\n",
    "This image includes:\n",
    "- Apache Spark 2.x\n",
    "- Python 3 with PySpark\n",
    "- Jupyter Notebook environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4334906",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 2: Run the Spark Container\n",
    "Run the container and expose Jupyter on port 8888.\n",
    "```bash\n",
    "docker run -p 8888:8888 --name spark jupyter/all-spark-notebook:95f855f8e55f\n",
    "```\n",
    "### Explanation\n",
    "- `-p 8888:8888` ‚Üí Maps container port to host port.\n",
    "- `--name spark` ‚Üí Assigns the container name.\n",
    "- Image tag ‚Üí Specifies the Spark version image.\n",
    "\n",
    "After running, you‚Äôll see an output similar to:\n",
    "```\n",
    "http://127.0.0.1:8888/?token=<unique_token>\n",
    "```\n",
    "Open this link in a browser to access Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba84bcd1",
   "metadata": {},
   "source": [
    "## üìä Step 3: Verify Spark Installation\n",
    "After accessing Jupyter, open a new notebook and verify Spark setup:\n",
    "```python\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkSetupTest').getOrCreate()\n",
    "print(spark.version)\n",
    "spark.stop()\n",
    "```\n",
    "If setup is successful, Spark version 2.x.x should be displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2949ee3b",
   "metadata": {},
   "source": [
    "## üßπ Step 4: Stop and Remove Container (Optional)\n",
    "To stop and remove the container:\n",
    "```bash\n",
    "docker stop spark\n",
    "docker rm spark\n",
    "```\n",
    "---\n",
    "‚úÖ You now have an Apache Spark 2.x setup running inside Docker with Jupyter Notebook support."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
