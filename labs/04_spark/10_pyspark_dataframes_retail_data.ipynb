{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Retail data with PySpark — schemas, loads, and core operations\nReads retail CSV files from `/content` **without headers**, defines explicit schemas per dataset, and demonstrates common PySpark DataFrame operations and simple analytics.\n\n**Note:** Inputs have no header row, so every `.csv()` read uses `option('header', False)` and relies on the **column order** defined in each schema."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Imports"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, TimestampType",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Environment"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "spark = SparkSession.builder.appName(\"Retail-Data-PySpark\").getOrCreate()\nINPUT_ROOT = \"/content\"  # departments.csv, categories.csv, products.csv, customers.csv, orders.csv, order_items.csv (no headers)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## What are `StructType` and `StructField`?\n- **StructType** — the full table schema (an ordered list of fields). It is the blueprint Spark uses to interpret rows and enforce column names and data types when creating a DataFrame.\n- **StructField** — one column definition inside a StructType. It specifies the **name**, **data type** (e.g., `IntegerType`, `StringType`, `DoubleType`, `TimestampType`), whether the value may be **nullable**, and optional **metadata**.\nBecause inputs lack headers, **schema order must match the CSV column order**."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Create the orders schema"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "orders_schema = StructType([\n    StructField(\"order_id\", IntegerType(), True),\n    StructField(\"order_date\", TimestampType(), True),\n    StructField(\"order_customer_id\", IntegerType(), True),\n    StructField(\"order_status\", StringType(), True)\n])",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Load the orders dataset"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "orders = spark.read.option(\"header\", False).schema(orders_schema).csv(f\"{INPUT_ROOT}/orders.csv\")\norders.printSchema()\norders.show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Orders — to_date"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "orders.select(F.to_date(\"order_date\").alias(\"order_day\")).show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Orders — date_format yyyy-MM"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "orders.select(F.date_format(\"order_date\",\"yyyy-MM\").alias(\"year_month\")).show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Orders — extract year"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "orders.select(F.year(\"order_date\").alias(\"year\")).show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Orders — extract month"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "orders.select(F.month(\"order_date\").alias(\"month\")).show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Orders — extract day of month"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "orders.select(F.dayofmonth(\"order_date\").alias(\"day\")).show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Create the order items schema"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "order_items_schema = StructType([\n    StructField(\"order_item_id\", IntegerType(), True),\n    StructField(\"order_item_order_id\", IntegerType(), True),\n    StructField(\"order_item_product_id\", IntegerType(), True),\n    StructField(\"order_item_quantity\", IntegerType(), True),\n    StructField(\"order_item_subtotal\", DoubleType(), True),\n    StructField(\"order_item_product_price\", DoubleType(), True)\n])",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Load the order items dataset"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "order_items = spark.read.option(\"header\", False).schema(order_items_schema).csv(f\"{INPUT_ROOT}/order_items.csv\")\norder_items.printSchema()\norder_items.show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Order items — derive line_amount"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "oi = order_items.withColumn(\"line_amount\", F.col(\"order_item_quantity\") * F.col(\"order_item_product_price\"))\noi.select(\"order_item_id\",\"order_item_order_id\",\"line_amount\").show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Order items — filter quantity and price > 0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "order_items.where((F.col(\"order_item_quantity\") >= 1) & (F.col(\"order_item_product_price\") > 0)).show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Order items — between on subtotal (10.0–50.0)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "order_items.where(F.col(\"order_item_subtotal\").between(10.0, 50.0)).select(\"order_item_id\",\"order_item_subtotal\").show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Order items — sort by line_amount desc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "oi.orderBy(F.desc(\"line_amount\")).select(\"order_item_id\",\"order_item_order_id\",\"line_amount\").show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Order items — groupBy revenue per order"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "oi.groupBy(\"order_item_order_id\").agg(F.round(F.sum(\"line_amount\"),2).alias(\"order_revenue\")).orderBy(F.desc(\"order_revenue\")).show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Create the customers schema"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "customers_schema = StructType([\n    StructField(\"customer_id\", IntegerType(), True),\n    StructField(\"customer_fname\", StringType(), True),\n    StructField(\"customer_lname\", StringType(), True),\n    StructField(\"customer_email\", StringType(), True),\n    StructField(\"customer_password\", StringType(), True),\n    StructField(\"customer_street\", StringType(), True),\n    StructField(\"customer_city\", StringType(), True),\n    StructField(\"customer_state\", StringType(), True),\n    StructField(\"customer_zipcode\", StringType(), True)\n])",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Load the customers dataset"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "customers = spark.read.option(\"header\", False).schema(customers_schema).csv(f\"{INPUT_ROOT}/customers.csv\")\ncustomers.printSchema()\ncustomers.show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Customers — select & col (customer_id, customer_city)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "customers.select(F.col(\"customer_id\"), F.col(\"customer_city\")).show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Customers — selectExpr uppercase state"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "customers.selectExpr(\"customer_id\", \"upper(customer_state) as state_up\").show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Customers — withColumnRenamed first/last name"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "customers.withColumnRenamed(\"customer_fname\",\"first_name\").withColumnRenamed(\"customer_lname\",\"last_name\").select(\"first_name\",\"last_name\").show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Customers — concatenate full name"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "customers.select(F.concat_ws(\" \", F.col(\"customer_fname\"), F.col(\"customer_lname\")).alias(\"full_name\")).show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Customers — drop a single column (customer_password)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "customers.drop(\"customer_password\").show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Customers — drop rows where email is null"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "customers.na.drop(subset=[\"customer_email\"]).show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Create the categories schema"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "categories_schema = StructType([\n    StructField(\"category_id\", IntegerType(), True),\n    StructField(\"category_department_id\", IntegerType(), True),\n    StructField(\"category_name\", StringType(), True)\n])",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Load the categories dataset"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "categories = spark.read.option(\"header\", False).schema(categories_schema).csv(f\"{INPUT_ROOT}/categories.csv\")\ncategories.printSchema()\ncategories.show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Create the products schema"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "products_schema = StructType([\n    StructField(\"product_id\", IntegerType(), True),\n    StructField(\"product_category_id\", IntegerType(), True),\n    StructField(\"product_name\", StringType(), True),\n    StructField(\"product_description\", StringType(), True),\n    StructField(\"product_price\", DoubleType(), True),\n    StructField(\"product_image\", StringType(), True)\n])",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Load the products dataset"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "products = spark.read.option(\"header\", False).schema(products_schema).csv(f\"{INPUT_ROOT}/products.csv\")\nproducts.printSchema()\nproducts.show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Create the departments schema"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "departments_schema = StructType([\n    StructField(\"department_id\", IntegerType(), True),\n    StructField(\"department_name\", StringType(), True)\n])",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Load the departments dataset"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "departments = spark.read.option(\"header\", False).schema(departments_schema).csv(f\"{INPUT_ROOT}/departments.csv\")\ndepartments.printSchema()\ndepartments.show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Orders — filter where status == 'COMPLETE'"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "orders.where(F.col(\"order_status\") == \"COMPLETE\").select(\"order_id\",\"order_status\").show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Orders — filter where status != 'COMPLETE'"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "orders.where(F.col(\"order_status\") != \"COMPLETE\").select(\"order_id\",\"order_status\").show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Orders — filter where status IN ('CLOSED','COMPLETE')"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "orders.where( (F.col(\"order_status\") == \"CLOSED\") | (F.col(\"order_status\") == \"COMPLETE\") ).select(\"order_id\",\"order_status\").show(5, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Analytics — revenue for a specific order (order_id = 2)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "oi = order_items.withColumn(\"line_amount\", F.col(\"order_item_quantity\") * F.col(\"order_item_product_price\"))\noi.filter(F.col(\"order_item_order_id\")==2).agg(F.round(F.sum(\"line_amount\"),2).alias(\"revenue_for_order_2\")).show(truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Analytics — revenue by category"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "oi = order_items.withColumn(\"line_amount\", F.col(\"order_item_quantity\") * F.col(\"order_item_product_price\"))\nrev_by_cat = (oi.join(products, oi.order_item_product_id == products.product_id, \"left\")\n                .join(categories, products.product_category_id == categories.category_id, \"left\")\n                .groupBy(\"category_id\",\"category_name\")\n                .agg(F.round(F.sum(\"line_amount\"),2).alias(\"revenue\"))\n                .orderBy(F.desc(\"revenue\")))\nrev_by_cat.show(10, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Analytics — top products by revenue"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "oi = order_items.withColumn(\"line_amount\", F.col(\"order_item_quantity\") * F.col(\"order_item_product_price\"))\ntop_products = (oi.join(products, oi.order_item_product_id == products.product_id, \"left\")\n                  .groupBy(\"product_id\",\"product_name\")\n                  .agg(F.round(F.sum(\"line_amount\"),2).alias(\"revenue\"))\n                  .orderBy(F.desc(\"revenue\")))\ntop_products.show(10, truncate=False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Analytics — top customers by spend"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "oi = order_items.withColumn(\"line_amount\", F.col(\"order_item_quantity\") * F.col(\"order_item_product_price\"))\ncust_spend = (oi.join(orders, oi.order_item_order_id == orders.order_id, \"left\")\n                .join(customers, orders.order_customer_id == customers.customer_id, \"left\")\n                .groupBy(\"customer_id\",\n                         F.concat_ws(\" \", F.col(\"customer_fname\"), F.col(\"customer_lname\")).alias(\"customer_name\"))\n                .agg(F.round(F.sum(\"line_amount\"),2).alias(\"total_spend\"),\n                     F.countDistinct(\"order_id\").alias(\"orders\"))\n                .orderBy(F.desc(\"total_spend\")))\ncust_spend.show(10, truncate=False)",
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}