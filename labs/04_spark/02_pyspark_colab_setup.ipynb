{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "808d7ca2",
   "metadata": {},
   "source": [
    "# PySpark Setup in Google Colab\n",
    "This notebook provides a step-by-step guide to set up Spark in Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34d4409",
   "metadata": {},
   "source": [
    "## Step 1: Launch Colab\n",
    "Open Google Colab using the following link:\n",
    "[Google Colab](https://colab.research.google.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddfee1b",
   "metadata": {},
   "source": [
    "## Step 2: Setup Spark\n",
    "Install Java, Spark, and Findspark, and configure environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9fb4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Java, Spark, and Findspark in one go\n",
    "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
    "!wget -q https://archive.apache.org/dist/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n",
    "!tar xf spark-3.5.1-bin-hadoop3.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "# Environment setup and SparkSession start\n",
    "import os, findspark\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.1-bin-hadoop3\"\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Colab-PySpark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534ccb2a",
   "metadata": {},
   "source": [
    "## Step 3: Test Spark\n",
    "Run the following code to confirm that Spark is working properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb02a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
